{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86f238db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import classification_report, log_loss, accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f0f74ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = r''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bb13120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'add', 'dec', 'div', 'eq', 'mul', 'sub', 'x', 'y', 'z']\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "Name=[]\n",
    "for file in os.listdir(directory):\n",
    "    if file!='.directory':\n",
    "        Name+=[file]\n",
    "print(Name)\n",
    "print(len(Name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d1dfe13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, 'add': 10, 'dec': 11, 'div': 12, 'eq': 13, 'mul': 14, 'sub': 15, 'x': 16, 'y': 17, 'z': 18}\n",
      "{0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: 'add', 11: 'dec', 12: 'div', 13: 'eq', 14: 'mul', 15: 'sub', 16: 'x', 17: 'y', 18: 'z'}\n"
     ]
    }
   ],
   "source": [
    "N=[]\n",
    "for i in range(len(Name)):\n",
    "    N+=[i]\n",
    "    \n",
    "normal_mapping=dict(zip(Name,N)) \n",
    "reverse_mapping=dict(zip(N,Name))\n",
    "print(normal_mapping)\n",
    "print(reverse_mapping)\n",
    "def mapper(value):\n",
    "    return reverse_mapping[value]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "637bc7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=[]\n",
    "testset=[]\n",
    "count=0\n",
    "for name in Name:\n",
    "    path=os.path.join(directory,name)\n",
    "    t=0\n",
    "    for im in os.listdir(path):\n",
    "        if im[-4:]=='.jpg' or im[-4:]=='.png':\n",
    "            # print(im)\n",
    "            image=load_img(os.path.join(path,im), grayscale=False, color_mode='rgb', target_size=(40,40))\n",
    "            image=img_to_array(image)\n",
    "            image=image/255.0\n",
    "            if t<400:\n",
    "                dataset.append([image,count])\n",
    "            else:   \n",
    "                testset.append([image,count])\n",
    "            t+=1\n",
    "    count=count+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab36e414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(testset[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c68fec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data,labels0=zip(*dataset)\n",
    "test,tlabels0=zip(*testset)\n",
    "# print(labels0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "895730ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7411, 40, 40, 3)\n",
      "(7411, 19)\n"
     ]
    }
   ],
   "source": [
    "labels1=to_categorical(labels0)\n",
    "data=np.array(data)\n",
    "labels=np.array(labels1)\n",
    "print(data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8013c606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2660, 40, 40, 3)\n",
      "(2660, 17)\n"
     ]
    }
   ],
   "source": [
    "tlabels1=to_categorical(tlabels0)\n",
    "test=np.array(test)\n",
    "tlabels=np.array(tlabels1)\n",
    "print(test.shape)\n",
    "print(tlabels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "258b3175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5928, 40, 40, 3)\n",
      "(1483, 40, 40, 3)\n",
      "(5928, 19)\n",
      "(1483, 19)\n"
     ]
    }
   ],
   "source": [
    "trainx,testx,trainy,testy=train_test_split(data,labels,test_size=0.2,random_state=1)\n",
    "print(trainx.shape)\n",
    "print(testx.shape)\n",
    "print(trainy.shape)\n",
    "print(testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d517cf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(horizontal_flip=True,vertical_flip=True,rotation_range=20,zoom_range=0.2,\n",
    "                        width_shift_range=0.2,height_shift_range=0.2,shear_range=0.1,fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df783ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = tf.keras.applications.DenseNet201(input_shape=(40,40,3),include_top=False,weights='imagenet',pooling='avg')\n",
    "pretrained_model.trainable = False\n",
    "#pretrained_model.compile(optimizer='adam',losbs='categorical_crossentropy',metrics=['accuracy'])\n",
    "#pretrained_model.fit(datagen.flow(trainx,trainy,batch_size=32),validation_data=(testx,testy),epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69b2429a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_11/Relu:0\", shape=(None, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "inputs = pretrained_model.input\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\n",
    "outputs = tf.keras.layers.Dense(19, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e54a98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2ff94bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "186/186 [==============================] - 45s 240ms/step - loss: 1.6255 - accuracy: 0.5002 - val_loss: 0.9743 - val_accuracy: 0.7100\n",
      "Epoch 2/15\n",
      "186/186 [==============================] - 42s 225ms/step - loss: 1.0602 - accuracy: 0.6544 - val_loss: 0.7586 - val_accuracy: 0.7613\n",
      "Epoch 3/15\n",
      "186/186 [==============================] - 42s 224ms/step - loss: 0.9522 - accuracy: 0.6918 - val_loss: 0.6740 - val_accuracy: 0.7862\n",
      "Epoch 4/15\n",
      "186/186 [==============================] - 42s 224ms/step - loss: 0.8601 - accuracy: 0.7147 - val_loss: 0.5860 - val_accuracy: 0.8213\n",
      "Epoch 5/15\n",
      "186/186 [==============================] - 42s 223ms/step - loss: 0.8037 - accuracy: 0.7289 - val_loss: 0.5473 - val_accuracy: 0.8307\n",
      "Epoch 6/15\n",
      "186/186 [==============================] - 41s 223ms/step - loss: 0.7920 - accuracy: 0.7389 - val_loss: 0.5251 - val_accuracy: 0.8301\n",
      "Epoch 7/15\n",
      "186/186 [==============================] - 42s 225ms/step - loss: 0.7486 - accuracy: 0.7535 - val_loss: 0.5046 - val_accuracy: 0.8328\n",
      "Epoch 8/15\n",
      "186/186 [==============================] - 42s 224ms/step - loss: 0.7368 - accuracy: 0.7524 - val_loss: 0.5037 - val_accuracy: 0.8436\n",
      "Epoch 9/15\n",
      "186/186 [==============================] - 41s 223ms/step - loss: 0.7211 - accuracy: 0.7637 - val_loss: 0.4846 - val_accuracy: 0.8328\n",
      "Epoch 10/15\n",
      "186/186 [==============================] - 42s 228ms/step - loss: 0.6945 - accuracy: 0.7675 - val_loss: 0.4850 - val_accuracy: 0.8321\n",
      "Epoch 11/15\n",
      "186/186 [==============================] - 41s 222ms/step - loss: 0.6904 - accuracy: 0.7648 - val_loss: 0.4517 - val_accuracy: 0.8436\n",
      "Epoch 12/15\n",
      "186/186 [==============================] - 41s 222ms/step - loss: 0.7008 - accuracy: 0.7704 - val_loss: 0.3997 - val_accuracy: 0.8719\n",
      "Epoch 13/15\n",
      "186/186 [==============================] - 42s 224ms/step - loss: 0.6598 - accuracy: 0.7778 - val_loss: 0.4572 - val_accuracy: 0.8530\n",
      "Epoch 14/15\n",
      "186/186 [==============================] - 41s 222ms/step - loss: 0.6535 - accuracy: 0.7768 - val_loss: 0.4820 - val_accuracy: 0.8348\n",
      "Epoch 15/15\n",
      "186/186 [==============================] - 42s 225ms/step - loss: 0.6316 - accuracy: 0.7881 - val_loss: 0.4201 - val_accuracy: 0.8584\n"
     ]
    }
   ],
   "source": [
    "fitted_model=model.fit(datagen.flow(trainx,trainy,batch_size=32),validation_data=(testx,testy),epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e4bf42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93        81\n",
      "           1       0.94      0.91      0.93        69\n",
      "           2       0.77      0.55      0.64        73\n",
      "           3       0.82      0.75      0.79        81\n",
      "           4       0.67      0.84      0.75        69\n",
      "           5       0.64      0.83      0.72        81\n",
      "           6       0.69      0.81      0.74        84\n",
      "           7       0.88      0.83      0.85        86\n",
      "           8       0.85      0.93      0.89        72\n",
      "           9       0.76      0.61      0.68        89\n",
      "          10       0.99      0.93      0.96        83\n",
      "          11       1.00      0.94      0.97        84\n",
      "          12       1.00      0.89      0.94        82\n",
      "          13       0.89      0.96      0.92        76\n",
      "          14       0.96      0.90      0.93        84\n",
      "          15       0.95      0.97      0.96        91\n",
      "          16       0.88      0.96      0.92        82\n",
      "          17       0.87      0.84      0.85        73\n",
      "          18       0.95      0.98      0.97        43\n",
      "\n",
      "    accuracy                           0.86      1483\n",
      "   macro avg       0.87      0.86      0.86      1483\n",
      "weighted avg       0.86      0.86      0.86      1483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(testx)\n",
    "pred=np.argmax(y_pred,axis=1)\n",
    "ground = np.argmax(testy,axis=1)\n",
    "print(classification_report(ground,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5a1e1c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACgAAAAoCAIAAAADnC86AAABGElEQVR4nO2W0RGDMAhASa8T+OcS6qeO4Bzu4D4u4Rpu4a8j0A/OVKNiwFxtr+ErcoQXSAANIsId8riFGsERHMF/DjbGfBRsZrHrI8uu67jDoURoS57njubIkvFv/IcEHX9rv9UfWS7l6UkFgKqqdvWISDmnhVXy3gQRc17Wd+njM3w5eUYSANz3vWJXgFQv8+zv7WrEOupV8JXmFaxlSq9MCc6yTLfxLaKWue2IwzDonGhetfOgqGdJnWim05Ja17XUgxIMAEVRwPyayrLUgWVZ2q1az1Q7I0v5qh0SX9DTNFkDu9CAHSp97rJpXCZJAgBt264qQlpCpwXmSNM0wcqJERt3mqbjOHKWYcH+8oP/1REcwd8KfgEfZI8G7k2bgAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=40x40 at 0x1DA53E94220>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_img(r'C:\\Users\\Muhammad Haris\\dataset\\x\\0N69wLku.png',target_size=(40,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97813bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image=load_img(r'C:\\Users\\Muhammad Haris\\dataset\\x\\0N69wLku.png',target_size=(40,40))\n",
    "\n",
    "image=img_to_array(image) \n",
    "image=image/255.0\n",
    "prediction_image=np.array(image)\n",
    "prediction_image= np.expand_dims(image, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d0b7ed97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is x.\n"
     ]
    }
   ],
   "source": [
    "prediction=model.predict(prediction_image)\n",
    "value=np.argmax(prediction)\n",
    "move_name=mapper(value)\n",
    "print(\"Prediction is {}.\".format(move_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffcb032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
